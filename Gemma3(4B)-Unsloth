{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Gemma 3 Fine Tuning via Unsloth library\n\n- This will be a fine tuning using public dataset to simulate in-domain fine tuning\n- Using the 4B model as a reference for training the 12B and 27B 'it' (instruction tuned) models provided by Unsloth\n\n### Why Unsloth?\n- Unsloth makes Gemma 3 (12B) finetuning 1.6x faster, use 60% less VRAM, and enables 6x longer than environments with Flash Attention 2 on a 48GB GPU. (ref: https://unsloth.ai/blog/gemma3#fixes)\n\n1. USP's\n   - Unsloth utilises dynamic 4-bit quants for increased accuracy\n   - Future scaling to Group Relative Policy Optimisation (GRPO)\n3. Gemma 3 Quirks\n   - Using FP16 on T4 GPU's provided by Kaggle results in gradients & activations reaching infinity\n   - Newer GPU's with BF16 tensorcores will not face this issue","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"## Library Installation","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install unsloth vllm\n!pip install --force-reinstall --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git\n!pip install git+https://github.com/huggingface/transformers.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T06:39:44.548799Z","iopub.execute_input":"2025-05-06T06:39:44.549080Z","iopub.status.idle":"2025-05-06T06:43:50.980597Z","shell.execute_reply.started":"2025-05-06T06:39:44.549058Z","shell.execute_reply":"2025-05-06T06:43:50.979327Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# %%capture\n# !pip install unsloth vllm\n# !pip install torch==2.6.0 torchaudio==2.6.0 torchvision==2.6.0 --index-url https://download.pytorch.org/whl/cu126 # or the appropriate CUDA version\n# !pip install triton==3.2.0\n# !pip install --force-reinstall --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git\n# !pip install git+https://github.com/huggingface/transformers.git","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"garbage_collection_threshold:0.6,max_split_size_mb:128\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T06:03:28.540407Z","iopub.execute_input":"2025-05-06T06:03:28.540715Z","iopub.status.idle":"2025-05-06T06:03:28.545161Z","shell.execute_reply.started":"2025-05-06T06:03:28.540692Z","shell.execute_reply":"2025-05-06T06:03:28.544432Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!pip freeze | grep triton","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T06:03:41.423720Z","iopub.execute_input":"2025-05-06T06:03:41.424006Z","iopub.status.idle":"2025-05-06T06:03:43.160936Z","shell.execute_reply.started":"2025-05-06T06:03:41.423984Z","shell.execute_reply":"2025-05-06T06:03:43.159956Z"}},"outputs":[{"name":"stdout","text":"triton==3.3.0\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pip freeze | grep torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T06:12:40.240927Z","iopub.execute_input":"2025-05-06T06:12:40.241237Z","iopub.status.idle":"2025-05-06T06:12:41.959499Z","shell.execute_reply.started":"2025-05-06T06:12:40.241216Z","shell.execute_reply":"2025-05-06T06:12:41.958545Z"}},"outputs":[{"name":"stdout","text":"pytorch-ignite==0.5.2\npytorch-lightning==2.5.1\ntorch==2.7.0\ntorchao==0.10.0\ntorchaudio @ https://download.pytorch.org/whl/cu124/torchaudio-2.5.1%2Bcu124-cp311-cp311-linux_x86_64.whl\ntorchdata==0.11.0\ntorchinfo==1.8.0\ntorchmetrics==1.7.1\ntorchsummary==1.5.1\ntorchtune==0.6.1\ntorchvision==0.22.0\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"!nvcc --version","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T06:22:32.331199Z","iopub.execute_input":"2025-05-06T06:22:32.331891Z","iopub.status.idle":"2025-05-06T06:22:32.543957Z","shell.execute_reply.started":"2025-05-06T06:22:32.331859Z","shell.execute_reply":"2025-05-06T06:22:32.543152Z"}},"outputs":[{"name":"stdout","text":"nvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2024 NVIDIA Corporation\nBuilt on Thu_Jun__6_02:18:23_PDT_2024\nCuda compilation tools, release 12.5, V12.5.82\nBuild cuda_12.5.r12.5/compiler.34385749_0\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"## Setup Unsloth\n- includes LoRA adapters","metadata":{}},{"cell_type":"code","source":"from unsloth import FastModel\nimport torch\n\nfourbit_models = [\n    # 4bit dynamic quants for superior accuracy and low memory use\n    \"unsloth/gemma-3-1b-it-unsloth-bnb-4bit\",\n    \"unsloth/gemma-3-4b-it-unsloth-bnb-4bit\",\n    \"unsloth/gemma-3-12b-it-unsloth-bnb-4bit\",\n    \"unsloth/gemma-3-27b-it-unsloth-bnb-4bit\",\n\n    # Other popular models!\n    \"unsloth/Llama-3.1-8B\",\n    \"unsloth/Llama-3.2-3B\",\n    \"unsloth/Llama-3.3-70B\",\n    \"unsloth/mistral-7b-instruct-v0.3\",\n    \"unsloth/Phi-4\",\n] # More models at https://huggingface.co/unsloth\n\nmodel, tokenizer = FastModel.from_pretrained(\n    model_name = \"unsloth/gemma-3-4b-it\",\n    max_seq_length = 1024, # Choose any for long context!\n    load_in_4bit = True,  # 4 bit quantization to reduce memory\n    load_in_8bit = False, # [NEW!] A bit more accurate, uses 2x memory\n    full_finetuning = False, # [NEW!] We have full finetuning now!\n    # token = \"hf_...\", # use one if using gated models\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T06:43:50.982616Z","iopub.execute_input":"2025-05-06T06:43:50.982868Z","iopub.status.idle":"2025-05-06T06:45:04.018731Z","shell.execute_reply.started":"2025-05-06T06:43:50.982846Z","shell.execute_reply":"2025-05-06T06:45:04.018136Z"}},"outputs":[{"name":"stdout","text":"🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","output_type":"stream"},{"name":"stderr","text":"2025-05-06 06:44:01.578071: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746513841.799885      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746513841.865878      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"🦥 Unsloth Zoo will now patch everything to make training faster!\nINFO 05-06 06:44:19 [importing.py:53] Triton module has been replaced with a placeholder.\nINFO 05-06 06:44:19 [__init__.py:239] Automatically detected platform cuda.\n==((====))==  Unsloth 2025.4.8: Fast Gemma3 patching. Transformers: 4.52.0.dev0. vLLM: 0.8.5.post1.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post2. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\nUnsloth: Using float16 precision for gemma3 won't work! Using float32.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/4.56G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72ea21acccb740a985365a32c0cd0ae3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/210 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ed66a822c8246fd9f0961eee79aee45"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"processor_config.json:   0%|          | 0.00/70.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfc479e96d4a4842a8b8c16d4f67d950"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"chat_template.json:   0%|          | 0.00/1.61k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"456f36365c3a4052a624e78fc678fd5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"chat_template.jinja:   0%|          | 0.00/1.53k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f566bfaa0614e17b24b0bc332d03d57"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87e548e944c74bee847fce5aec337345"}},"metadata":{}},{"name":"stderr","text":"Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.16M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42155b0e9c994528980d2ca9a74ad57f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a52ff330a42436bb215dd7aaa430167"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd3190aa538245b49ea4a99eca2d812e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9f23d7af83040198bec060d58aba7b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/670 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c145b9f1ccaa43e9bc5f88a40b4e5b06"}},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"Include the LoRA declaration for faster training","metadata":{}},{"cell_type":"code","source":"model = FastModel.get_peft_model(\n    model,\n    finetune_vision_layers     = False, # Turn off for just text!\n    finetune_language_layers   = True,  # Should leave on!\n    finetune_attention_modules = True,  # Attention good for GRPO\n    finetune_mlp_modules       = True,  # SHould leave on always!\n\n    r = 8,           # Larger = higher accuracy, but might overfit\n    lora_alpha = 8,  # Recommended alpha == r at least\n    lora_dropout = 0,\n    bias = \"none\",\n    random_state = 3407,\n\n    # use_gradient_checkpointing = False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T06:45:04.019495Z","iopub.execute_input":"2025-05-06T06:45:04.019731Z","iopub.status.idle":"2025-05-06T06:45:09.172287Z","shell.execute_reply.started":"2025-05-06T06:45:04.019712Z","shell.execute_reply":"2025-05-06T06:45:09.171694Z"}},"outputs":[{"name":"stdout","text":"Unsloth: Making `model.base_model.model.language_model.model` require gradients\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## Data Preparation\n1. Since `Gemma-3` has its own chat template, we can access it with Unsloth. This helps to format conversation styles.\n2. Dataset used is the `Maxime Labonne's FineTome-100k` dataset, Gemma-3 renders multi turn conversations like below:\n\n```\n<bos><start_of_turn>user\nHello!<end_of_turn>\n<start_of_turn>model\nHey there!<end_of_turn>\n```","metadata":{}},{"cell_type":"code","source":"from unsloth.chat_templates import get_chat_template\ntokenizer = get_chat_template(\n    tokenizer,\n    chat_template = \"gemma-3\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T06:45:09.174057Z","iopub.execute_input":"2025-05-06T06:45:09.174311Z","iopub.status.idle":"2025-05-06T06:45:09.178878Z","shell.execute_reply.started":"2025-05-06T06:45:09.174293Z","shell.execute_reply":"2025-05-06T06:45:09.178344Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from datasets import load_dataset\ndataset = load_dataset(\"mlabonne/FineTome-100k\", split = \"train\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T06:45:09.179534Z","iopub.execute_input":"2025-05-06T06:45:09.179760Z","iopub.status.idle":"2025-05-06T06:45:12.538474Z","shell.execute_reply.started":"2025-05-06T06:45:09.179734Z","shell.execute_reply":"2025-05-06T06:45:12.537692Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/982 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6ce05be38534f6db44421756b1a374d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/117M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50f274b8a53e4d55b85147df378fc027"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/100000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba5ca0dfc33843d7bc628ed012475473"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"from unsloth.chat_templates import standardize_data_formats\ndataset = standardize_data_formats(dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T06:45:12.539504Z","iopub.execute_input":"2025-05-06T06:45:12.539802Z","iopub.status.idle":"2025-05-06T06:45:14.978877Z","shell.execute_reply.started":"2025-05-06T06:45:12.539781Z","shell.execute_reply":"2025-05-06T06:45:14.978183Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Unsloth: Standardizing formats (num_proc=4):   0%|          | 0/100000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98ce31daf96341ebaf8968588aa27d6d"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# check data\ndataset[100]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T06:45:14.980351Z","iopub.execute_input":"2025-05-06T06:45:14.980683Z","iopub.status.idle":"2025-05-06T06:45:14.986588Z","shell.execute_reply.started":"2025-05-06T06:45:14.980648Z","shell.execute_reply":"2025-05-06T06:45:14.986031Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{'conversations': [{'content': 'What is the modulus operator in programming and how can I use it to calculate the modulus of two given numbers?',\n   'role': 'user'},\n  {'content': 'In programming, the modulus operator is represented by the \\'%\\' symbol. It calculates the remainder when one number is divided by another. To calculate the modulus of two given numbers, you can use the modulus operator in the following way:\\n\\n```python\\n# Calculate the modulus\\nModulus = a % b\\n\\nprint(\"Modulus of the given numbers is: \", Modulus)\\n```\\n\\nIn this code snippet, the variables \\'a\\' and \\'b\\' represent the two given numbers for which you want to calculate the modulus. By using the modulus operator \\'%\\', we calculate the remainder when \\'a\\' is divided by \\'b\\'. The result is then stored in the variable \\'Modulus\\'. Finally, the modulus value is printed using the \\'print\\' statement.\\n\\nFor example, if \\'a\\' is 10 and \\'b\\' is 4, the modulus calculation would be 10 % 4, which equals 2. Therefore, the output of the above code would be:\\n\\n```\\nModulus of the given numbers is: 2\\n```\\n\\nThis means that the modulus of 10 and 4 is 2.',\n   'role': 'assistant'}],\n 'source': 'infini-instruct-top-500k',\n 'score': 4.774171352386475}"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"We now have to apply the chat template for `Gemma-3` onto the conversations, and save it to `text`. We remove the `<bos>` token using removeprefix(`'<bos>'`) since we're finetuning. The Processor will add this token before training and the model expects only one.","metadata":{}},{"cell_type":"code","source":"def formatting_prompts_func(examples):\n   convos = examples[\"conversations\"]\n   texts = [tokenizer.apply_chat_template(convo, tokenize = False, add_generation_prompt = False).removeprefix('<bos>') for convo in convos]\n   return { \"text\" : texts, }\n\ndataset = dataset.map(formatting_prompts_func, batched = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T06:45:14.987344Z","iopub.execute_input":"2025-05-06T06:45:14.987656Z","iopub.status.idle":"2025-05-06T06:45:27.961592Z","shell.execute_reply.started":"2025-05-06T06:45:14.987626Z","shell.execute_reply":"2025-05-06T06:45:27.960824Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f8985cf81bf4317a7492439c38ae83e"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"dataset[100][\"text\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T06:45:27.962826Z","iopub.execute_input":"2025-05-06T06:45:27.963074Z","iopub.status.idle":"2025-05-06T06:45:27.968656Z","shell.execute_reply.started":"2025-05-06T06:45:27.963057Z","shell.execute_reply":"2025-05-06T06:45:27.967905Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"'<start_of_turn>user\\nWhat is the modulus operator in programming and how can I use it to calculate the modulus of two given numbers?<end_of_turn>\\n<start_of_turn>model\\nIn programming, the modulus operator is represented by the \\'%\\' symbol. It calculates the remainder when one number is divided by another. To calculate the modulus of two given numbers, you can use the modulus operator in the following way:\\n\\n```python\\n# Calculate the modulus\\nModulus = a % b\\n\\nprint(\"Modulus of the given numbers is: \", Modulus)\\n```\\n\\nIn this code snippet, the variables \\'a\\' and \\'b\\' represent the two given numbers for which you want to calculate the modulus. By using the modulus operator \\'%\\', we calculate the remainder when \\'a\\' is divided by \\'b\\'. The result is then stored in the variable \\'Modulus\\'. Finally, the modulus value is printed using the \\'print\\' statement.\\n\\nFor example, if \\'a\\' is 10 and \\'b\\' is 4, the modulus calculation would be 10 % 4, which equals 2. Therefore, the output of the above code would be:\\n\\n```\\nModulus of the given numbers is: 2\\n```\\n\\nThis means that the modulus of 10 and 4 is 2.<end_of_turn>\\n'"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"## Model Training","metadata":{}},{"cell_type":"code","source":"from trl import SFTTrainer, SFTConfig\ntrainer = SFTTrainer(\n    model = model,\n    tokenizer = tokenizer,\n    train_dataset = dataset,\n    eval_dataset = None, # Can set up evaluation!\n    args = SFTConfig(\n        dataset_text_field = \"text\",\n        per_device_train_batch_size = 2,\n        gradient_accumulation_steps = 4, # Use GA to mimic batch size!\n        warmup_steps = 5,\n        # num_train_epochs = 1, # Set this for 1 full training run.\n        max_steps = 30,\n        learning_rate = 2e-5, # Reduce to 2e-5 for long training runs\n        logging_steps = 1,\n        optim = \"adamw_8bit\",\n        weight_decay = 0.01,\n        lr_scheduler_type = \"linear\",\n        seed = 3407,\n        report_to = \"none\", # Use this for WandB etc\n        dataset_num_proc=2,\n        fp16=False,\n    ),\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T06:45:27.970856Z","iopub.execute_input":"2025-05-06T06:45:27.971057Z","iopub.status.idle":"2025-05-06T06:47:03.306074Z","shell.execute_reply.started":"2025-05-06T06:45:27.971043Z","shell.execute_reply":"2025-05-06T06:47:03.305255Z"}},"outputs":[{"name":"stdout","text":"Unsloth: Switching to float32 training since model cannot work with float16\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Unsloth: Tokenizing [\"text\"] (num_proc=2):   0%|          | 0/100000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ccabbe9c025491d9b578752ffeb1234"}},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"Use Unsloths `train_on_completions` method to train only the assistant outputs and ignore loss on user's inputs. This will help improve finetuning accuracy.","metadata":{}},{"cell_type":"code","source":"from unsloth.chat_templates import train_on_responses_only\ntrainer = train_on_responses_only(\n    trainer,\n    instruction_part = \"<start_of_turn>user\\n\",\n    response_part = \"<start_of_turn>model\\n\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T06:47:03.307067Z","iopub.execute_input":"2025-05-06T06:47:03.307331Z","iopub.status.idle":"2025-05-06T06:47:28.089588Z","shell.execute_reply.started":"2025-05-06T06:47:03.307308Z","shell.execute_reply":"2025-05-06T06:47:28.088816Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/100000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"685a8b72cf3d4e799cff232bedd0c9e9"}},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"check if instruction part is properly masked - i.e. only one `<bos>` token in sample","metadata":{}},{"cell_type":"code","source":"tokenizer.decode(trainer.train_dataset[100][\"input_ids\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T06:47:28.090556Z","iopub.execute_input":"2025-05-06T06:47:28.090854Z","iopub.status.idle":"2025-05-06T06:47:28.097944Z","shell.execute_reply.started":"2025-05-06T06:47:28.090821Z","shell.execute_reply":"2025-05-06T06:47:28.097233Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"'<bos><start_of_turn>user\\nWhat is the modulus operator in programming and how can I use it to calculate the modulus of two given numbers?<end_of_turn>\\n<start_of_turn>model\\nIn programming, the modulus operator is represented by the \\'%\\' symbol. It calculates the remainder when one number is divided by another. To calculate the modulus of two given numbers, you can use the modulus operator in the following way:\\n\\n```python\\n# Calculate the modulus\\nModulus = a % b\\n\\nprint(\"Modulus of the given numbers is: \", Modulus)\\n```\\n\\nIn this code snippet, the variables \\'a\\' and \\'b\\' represent the two given numbers for which you want to calculate the modulus. By using the modulus operator \\'%\\', we calculate the remainder when \\'a\\' is divided by \\'b\\'. The result is then stored in the variable \\'Modulus\\'. Finally, the modulus value is printed using the \\'print\\' statement.\\n\\nFor example, if \\'a\\' is 10 and \\'b\\' is 4, the modulus calculation would be 10 % 4, which equals 2. Therefore, the output of the above code would be:\\n\\n```\\nModulus of the given numbers is: 2\\n```\\n\\nThis means that the modulus of 10 and 4 is 2.<end_of_turn>\\n'"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"check if masked out example is correct","metadata":{}},{"cell_type":"code","source":"tokenizer.decode([tokenizer.pad_token_id if x == -100 else x for x in trainer.train_dataset[100][\"labels\"]]).replace(tokenizer.pad_token, \" \")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T06:47:28.098757Z","iopub.execute_input":"2025-05-06T06:47:28.099120Z","iopub.status.idle":"2025-05-06T06:47:28.801827Z","shell.execute_reply.started":"2025-05-06T06:47:28.099097Z","shell.execute_reply":"2025-05-06T06:47:28.801055Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"'                               In programming, the modulus operator is represented by the \\'%\\' symbol. It calculates the remainder when one number is divided by another. To calculate the modulus of two given numbers, you can use the modulus operator in the following way:\\n\\n```python\\n# Calculate the modulus\\nModulus = a % b\\n\\nprint(\"Modulus of the given numbers is: \", Modulus)\\n```\\n\\nIn this code snippet, the variables \\'a\\' and \\'b\\' represent the two given numbers for which you want to calculate the modulus. By using the modulus operator \\'%\\', we calculate the remainder when \\'a\\' is divided by \\'b\\'. The result is then stored in the variable \\'Modulus\\'. Finally, the modulus value is printed using the \\'print\\' statement.\\n\\nFor example, if \\'a\\' is 10 and \\'b\\' is 4, the modulus calculation would be 10 % 4, which equals 2. Therefore, the output of the above code would be:\\n\\n```\\nModulus of the given numbers is: 2\\n```\\n\\nThis means that the modulus of 10 and 4 is 2.<end_of_turn>\\n'"},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"### Show GPU memory Stats","metadata":{}},{"cell_type":"code","source":"# @title Show current memory stats\ngpu_stats = torch.cuda.get_device_properties(0)\nstart_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\nmax_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\nprint(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\nprint(f\"{start_gpu_memory} GB of memory reserved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T06:47:28.802754Z","iopub.execute_input":"2025-05-06T06:47:28.803459Z","iopub.status.idle":"2025-05-06T06:47:28.816986Z","shell.execute_reply.started":"2025-05-06T06:47:28.803438Z","shell.execute_reply":"2025-05-06T06:47:28.816252Z"}},"outputs":[{"name":"stdout","text":"GPU = Tesla T4. Max memory = 14.741 GB.\n5.57 GB of memory reserved.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"Start Training","metadata":{}},{"cell_type":"code","source":"trainer_stats = trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T06:47:28.817745Z","iopub.execute_input":"2025-05-06T06:47:28.818013Z","iopub.status.idle":"2025-05-06T07:02:42.537009Z","shell.execute_reply.started":"2025-05-06T06:47:28.817987Z","shell.execute_reply":"2025-05-06T07:02:42.536254Z"}},"outputs":[{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n   \\\\   /|    Num examples = 100,000 | Num Epochs = 1 | Total steps = 30\nO^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 4\n\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 4 x 1) = 16\n \"-____-\"     Trainable parameters = 14,901,248/4,000,000,000 (0.37% trained)\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: Will smartly offload gradients to save VRAM!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [30/30 13:55, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.465800</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.574500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.523400</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.416400</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>1.393500</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>1.610600</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>1.537100</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>1.422800</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>1.807000</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>1.565800</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>1.539600</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>1.639900</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>1.190800</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>1.493900</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>1.744300</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>1.212500</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>1.146700</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>1.520400</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>1.313000</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.520600</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>1.605400</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>1.224500</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>1.291500</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>1.189900</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>1.615300</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>1.311100</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>1.416100</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>1.726700</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>1.194500</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.469800</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":15},{"cell_type":"markdown","source":"## Inference\n- According to the `Gemma-3` team, the recommended settings for inference are `temperature = 1.0, top_p = 0.95, top_k = 64`","metadata":{}},{"cell_type":"code","source":"from unsloth.chat_templates import get_chat_template\ntokenizer = get_chat_template(\n    tokenizer,\n    chat_template = \"gemma-3\",\n)\nmessages = [{\n    \"role\": \"user\",\n    \"content\": [{\n        \"type\" : \"text\",\n        \"text\" : \"Continue the sequence: 1, 1, 2, 3, 5, 8,\",\n    }]\n}]\ntext = tokenizer.apply_chat_template(\n    messages,\n    add_generation_prompt = True, # Must add for generation\n)\noutputs = model.generate(\n    **tokenizer([text], return_tensors = \"pt\").to(\"cuda\"),\n    max_new_tokens = 64, # Increase for longer outputs!\n    # Recommended Gemma-3 settings!\n    temperature = 1.0, top_p = 0.95, top_k = 64,\n)\ntokenizer.batch_decode(outputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:11:06.744534Z","iopub.execute_input":"2025-05-06T07:11:06.745772Z","iopub.status.idle":"2025-05-06T07:11:26.915677Z","shell.execute_reply.started":"2025-05-06T07:11:06.745742Z","shell.execute_reply":"2025-05-06T07:11:26.915029Z"}},"outputs":[{"name":"stderr","text":"You have set `compile_config`, but we are unable to meet the criteria for compilation. Compilation will be skipped.\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"['<bos><start_of_turn>user\\nContinue the sequence: 1, 1, 2, 3, 5, 8,<end_of_turn>\\n<start_of_turn>model\\n13, 21, 34...\\n\\nThis is the Fibonacci sequence, where each number is the sum of the two preceding ones.\\n<end_of_turn>']"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"messages = [{\n    \"role\": \"user\",\n    \"content\": [{\n        \"type\" : \"text\",\n        \"text\" : \"Compare and contrast the marketing strategies used by Tesla and Volkswagen for their electric vehicle offerings.\",\n    }]\n}]\ntext = tokenizer.apply_chat_template(\n    messages,\n    add_generation_prompt = True, # Must add for generation\n)\noutputs = model.generate(\n    **tokenizer([text], return_tensors = \"pt\").to(\"cuda\"),\n    max_new_tokens = 512, # Increase for longer outputs!\n    # Recommended Gemma-3 settings!\n    temperature = 1.0, top_p = 0.95, top_k = 64,\n)\ntokenizer.batch_decode(outputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:15:40.387746Z","iopub.execute_input":"2025-05-06T07:15:40.388574Z","iopub.status.idle":"2025-05-06T07:17:16.357595Z","shell.execute_reply.started":"2025-05-06T07:15:40.388544Z","shell.execute_reply":"2025-05-06T07:17:16.356930Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"['<bos><start_of_turn>user\\nCompare and contrast the marketing strategies used by Tesla and Volkswagen for their electric vehicle offerings.<end_of_turn>\\n<start_of_turn>model\\nTesla and Volkswagen, both major players in the EV market, have taken strikingly different approaches to marketing their electric vehicles. While both aim to capture the market, their strategies are fundamentally different, reflecting their corporate cultures and overall visions. Here’s a breakdown of their comparative approaches:\\n\\n**Tesla: The Disruptor – Brand-Centric & Experience-Driven**\\n\\n* **Core Strategy: Brand as Innovation & Aspiration:** Tesla’s marketing isn\\'t just about selling cars; it’s about selling a vision of the future. They’ve built a cult-like following around the idea of a sustainable, high-performance future powered by electric vehicles.\\n* **Key Tactics:**\\n    * **Elon Musk’s Personal Brand:** Elon Musk is arguably the single most important marketing asset for Tesla. His tweets, appearances, and even his personality drive conversation and demand.\\n    * **Direct-to-Consumer Sales (primarily):**  Tesla bypasses traditional dealerships, creating a unique and often controversial customer experience focused on online ordering, self-service charging, and limited service centers.\\n    * **Celebrity Endorsements & Brand Ambassadors:** While they\\'ve shifted slightly, they leverage celebrity endorsements (past examples include Oprah, Jay-Z), and focus on passionate owners as influencers.\\n    * **Community Building:** Tesla fosters a strong online community through forums, events, and Supercharger networks, creating a sense of belonging and shared excitement.\\n    * **Tech-Forward Positioning:** They constantly emphasize advancements in battery technology, autopilot, and software. \"Innovation\" is a central theme.\\n    * **Minimalist & Futuristic Aesthetics:** Their marketing materials and product design emphasize sleek lines, digital displays, and a futuristic vibe.\\n    * **Aggressive Pricing & Direct Communication:** Tesla tends to directly communicate about pricing and feature releases, bypassing traditional PR channels.\\n\\n\\n**Volkswagen: The Legacy Builder – Focus on Credibility & Traditional Marketing**\\n\\n* **Core Strategy:  Reclaiming the “Good German” Image:** Volkswagen is leveraging its established brand reputation and engineering prowess to re-establish itself as a serious EV player after the “Dieselgate” scandal. They’re emphasizing reliability, quality, and a practical approach.\\n* **Key Tactics:**\\n    * **Focus on Existing Brand Recognition:** They\\'re using their established Volkswagen name to gain trust and recognition, rather than building a new brand from scratch.\\n    * **Mass Media Campaigns:**  VW heavily relies on traditional advertising – TV commercials, print']"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"messages = [{\n    \"role\": \"user\",\n    \"content\": [{\n        \"type\" : \"text\",\n        \"text\" : \"How has the COVID-19 pandemic impacted the growth of the electric vehicle market, according to the data?\",\n    }]\n}]\ntext = tokenizer.apply_chat_template(\n    messages,\n    add_generation_prompt = True, # Must add for generation\n)\noutputs = model.generate(\n    **tokenizer([text], return_tensors = \"pt\").to(\"cuda\"),\n    max_new_tokens = 128, # Increase for longer outputs!\n    # Recommended Gemma-3 settings!\n    temperature = 1.0, top_p = 0.95, top_k = 64,\n)\ntokenizer.batch_decode(outputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:19:34.319181Z","iopub.execute_input":"2025-05-06T07:19:34.319572Z","iopub.status.idle":"2025-05-06T07:19:59.731604Z","shell.execute_reply.started":"2025-05-06T07:19:34.319546Z","shell.execute_reply":"2025-05-06T07:19:59.730807Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"[\"<bos><start_of_turn>user\\nHow has the COVID-19 pandemic impacted the growth of the electric vehicle market, according to the data?<end_of_turn>\\n<start_of_turn>model\\nOkay, let's break down how the COVID-19 pandemic impacted the growth of the electric vehicle (EV) market. The data paints a complex picture – initially a slowdown, followed by a surprisingly strong rebound and accelerated growth. Here's a breakdown of the key trends, supported by data:\\n\\n**1. Initial Slowdown (2020):**\\n\\n* **Sharp Decline in Sales:** The most immediate impact was a dramatic drop in vehicle sales globally, including EVs, in 2020.  Lockdowns, factory closures, and economic uncertainty led to a 40-60% decline in\"]"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"messages = [{\n    \"role\": \"user\",\n    \"content\": [{\n        \"type\" : \"text\",\n        \"text\" : \"List out 2 initiatives used by Tesla in marketing\",\n    }]\n}]\ntext = tokenizer.apply_chat_template(\n    messages,\n    add_generation_prompt = True, # Must add for generation\n)\noutputs = model.generate(\n    **tokenizer([text], return_tensors = \"pt\").to(\"cuda\"),\n    max_new_tokens = 128, # Increase for longer outputs!\n    # Recommended Gemma-3 settings!\n    temperature = 1.0, top_p = 0.95, top_k = 64,\n)\ntokenizer.batch_decode(outputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:28:42.765885Z","iopub.execute_input":"2025-05-06T07:28:42.766267Z","iopub.status.idle":"2025-05-06T07:29:06.730844Z","shell.execute_reply.started":"2025-05-06T07:28:42.766240Z","shell.execute_reply":"2025-05-06T07:29:06.730252Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"[\"<bos><start_of_turn>user\\nList out 2 initiatives used by Tesla in marketing<end_of_turn>\\n<start_of_turn>model\\nOkay, here are two prominent marketing initiatives consistently used by Tesla, with a bit of detail about each:\\n\\n1. **Referral Program (Tesla Referral Program):**\\n\\n   * **What it is:** Tesla's referral program is arguably one of their most effective marketing strategies. It's essentially a multi-tiered system that rewards existing Tesla owners for referring new customers.\\n   * **How it works:**\\n      * **Level 1 (Early Adopter):** Referred customers receive a $1,000 credit towards their Tesla purchase.\\n      * **Level 2 (Influencer):**  Referr\"]"},"metadata":{}}],"execution_count":22},{"cell_type":"markdown","source":"## Save model to FP16 vLLM\n- save it in the folder `gemma-3-finetune-unsloth`","metadata":{}},{"cell_type":"code","source":"model.save_pretrained_merged(\"gemma-3-4b-it-finetune-unsloth\", tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T05:56:58.634157Z","iopub.status.idle":"2025-05-06T05:56:58.634489Z","shell.execute_reply.started":"2025-05-06T05:56:58.634321Z","shell.execute_reply":"2025-05-06T05:56:58.634332Z"}},"outputs":[],"execution_count":null}]}